{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5768a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference for the code: https://www.kaggle.com/bmendes00/bird-image-classification-using-cnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d43213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp38-cp38-win_amd64.whl (35.1 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\cooki\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.60\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# to import cv2; might need to install opencv\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164df7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "433b460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8672a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_path = '../data/10-bird-species/train'\n",
    "birds = np.array(list(os.listdir(top_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba92958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'AFRICAN CROWNED CRANE', 1: 'AFRICAN FIREFINCH', 2: 'ALBATROSS', 3: 'ALEXANDRINE PARAKEET', 4: 'AMERICAN AVOCET', 5: 'AMERICAN BITTERN', 6: 'AMERICAN COOT', 7: 'AMERICAN GOLDFINCH', 8: 'AMERICAN KESTREL', 9: 'AMERICAN PIPIT'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_name = {i:x for (i,x) in enumerate(birds)}\n",
    "name_to_idx = {x:i for (i,x) in enumerate(birds)}\n",
    "print(idx_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d00786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_labels(path, birds, dim):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for bird in birds:\n",
    "        imgs = [cv2.resize(cv2.imread(img), dim, interpolation=cv2.INTER_AREA) for img in glob.glob(path + \"/\" + bird + \"/*.jpg\")]\n",
    "        for img in imgs:\n",
    "            data.append(img)\n",
    "            labels.append(name_to_idx[bird])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5192b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train = get_data_labels('../data/10-bird-species/train', idx_to_name.values(), (224,224))\n",
    "data_test, labels_test = get_data_labels('../data/10-bird-species/test', idx_to_name.values(), (224,224))\n",
    "data_valid, labels_valid = get_data_labels('../data/10-bird-species/valid', idx_to_name.values(), (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a75c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data = data / 255.0\n",
    "    data = data.astype('float32')\n",
    "    return data\n",
    "\n",
    "def one_hot(labels):\n",
    "    labels = np.eye(len(np.unique(labels)))[labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84cbda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = normalize(data_train)\n",
    "data_test = normalize(data_test)\n",
    "data_valid = normalize(data_valid)\n",
    "\n",
    "labels_train = one_hot(labels_train)\n",
    "labels_test = one_hot(labels_test)\n",
    "labels_valid = one_hot(labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f9e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66de282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freeze the extraction layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    " \n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7769db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# use “get_layer” method to save the last layer of the network\n",
    "last_layer = base_model.get_layer('block5_pool')\n",
    "# save the output of the last layer to be the input of the next layer\n",
    "last_output = last_layer.output\n",
    " \n",
    "# flatten the classifier input which is output of the last layer of VGG16 model\n",
    "x = Flatten()(last_output)\n",
    " \n",
    "# add our new softmax layer with 3 hidden units\n",
    "x = Dense(10, activation='softmax', name='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e796398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " softmax (Dense)             (None, 10)                250890    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,965,578\n",
      "Trainable params: 250,890\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate a new_model using keras’s Model class\n",
    "new_model = Model(inputs=base_model.input, outputs=x)\n",
    " \n",
    "# print the new_model summary\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "343d5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cooki\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cbbda72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1524/1524 [==============================] - 119s 78ms/step - loss: 0.7488 - accuracy: 0.7861 - val_loss: 0.1831 - val_accuracy: 0.9800\n",
      "Epoch 2/10\n",
      "1524/1524 [==============================] - 125s 82ms/step - loss: 0.1126 - accuracy: 0.9823 - val_loss: 0.1405 - val_accuracy: 0.9600\n",
      "Epoch 3/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 0.0351 - accuracy: 0.9987 - val_loss: 0.0853 - val_accuracy: 0.9600\n",
      "Epoch 4/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9400\n",
      "Epoch 5/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1524/1524 [==============================] - 127s 83ms/step - loss: 9.6090e-04 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9800\n",
      "Epoch 9/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 4.4377e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9800\n",
      "Epoch 10/10\n",
      "1524/1524 [==============================] - 126s 83ms/step - loss: 2.6511e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='birds.model.hdf5', save_best_only=True)\n",
    " \n",
    "history = new_model.fit(data_train, labels_train, steps_per_epoch=len(data_train),\n",
    "validation_data=(data_test, labels_test), validation_steps=3, epochs=10, verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65a1b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3feda2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'], 'b')\n",
    "plt.plot(history.history['val_loss'], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6210cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_valid, labels_valid):\n",
    "    predictions = model(data_valid)\n",
    "    wrong = 0\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if( np.argmax(pred) !=  np.argmax(labels_valid[i])):\n",
    "            wrong += 1\n",
    "    return (len(data_valid) - wrong) / len(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79ff01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# we use the validation data to verify the accuracy\n",
    "accuracy = get_accuracy(new_model, data_valid, labels_valid)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ae78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
